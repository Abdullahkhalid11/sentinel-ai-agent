{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ef497f",
   "metadata": {},
   "source": [
    "# Using tool to build an agent\n",
    "# Build an Agent with AgentExecutor (Legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f9858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: faiss-cpu in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: sentence_transformers in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (5.2.0)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (1.2.7)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain_community) (2.4.1)\n",
      "Requirement already satisfied: packaging in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (4.57.6)\n",
      "Requirement already satisfied: tqdm in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (1.17.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sentence_transformers) (4.15.0)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: filelock in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2026.1.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (80.10.1)\n",
      "Requirement already satisfied: colorama in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\agentic ai bootcamp_2\\langchain_tool_callling\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.14.3 soupsieve-2.8.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community faiss-cpu sentence_transformers beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a91f6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520c253d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "from langchain.chat_models import init_chat_model\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f5b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "if not tavily_api_key:\n",
    "    print(\"WARNING: TAVILY_API_KEY not found in environment variables. Please set it in your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8109b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=1, tavily_api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15688dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'January weather - Winter 2026 - Wah, Pakistan',\n",
       "  'url': 'https://www.weather-atlas.com/en/pakistan/wah-weather-january',\n",
       "  'content': '#### Frequently asked questions\\n\\nJanuary, with its high-temperature average of 17.3°C (63.1°F) and a low-temperature average of 6.7°C (44.1°F), is the coldest month.\\n\\nThe average high-temperature and low-temperature in Wah, Pakistan, during January are 17.3°C (63.1°F) and 6.7°C (44.1°F) respectively.\\n\\nThe average relative humidity in January in Wah, Pakistan, is 40%.\\n\\nIn Wah, Pakistan, in January, it is raining for 5.7 days, with typically 27mm (1.06\") of accumulated precipitation.\\n\\nIn January, the average day length in Wah, Pakistan, is 10h and 12min.\\n\\nOn the first day of January in Wah, sunrise is at 7:13 am and sunset at 5:10 pm. On the last day of the month, sunrise is at 7:06 am and sunset at 5:38 pm PKT. [...] With an average of 6.7h of sunshine, January has the least sunshine of the year in Wah, Pakistan.\\n\\nThe average sunshine duration in January in Wah is 6.7h.\\n\\nJanuary, February and December, with an average maximum UV index of 4, are months with the lowest UV index in Wah, Pakistan.\\n\\nIn Wah, the average daily maximum UV index in January is 4. A UV Index reading of 3 to 5 represents a moderate vulnerability from unsafe exposure to Sun\\'s UV rays.\\n\\nToday\\n\\nTomorrow\\n\\nLong-term\\n\\nYearJanuaryFMAMJJASOND\\n\\nDec\\n\\nJanuary\\n\\nFeb\\n\\nAverage high temperature\\n\\n19.5°C\\n\\n17.3°C\\n\\n18.9°C\\n\\nAverage low temperature\\n\\n8.7°C\\n\\n6.7°C\\n\\n8.8°C\\n\\nAverage pressure\\n\\n1018mbar\\n\\n1019.1mbar\\n\\n1017.3mbar\\n\\nAverage wind speed\\n\\n7.3km/h\\n\\n7.4km/h\\n\\n8.4km/h\\n\\nAverage max. wind speed\\n\\n7.9km/h\\n\\n8.1km/h\\n\\n9.1km/h\\n\\nAverage wind speed gusts [...] # January weather forecast Wah, Pakistan\\n\\nYearJanuaryFMAMJJASOND\\n\\n#### Weather in January\\n\\nJanuary, like December, in Wah, Pakistan, is another comfortable winter month, with an average temperature varying between 17.3°C (63.1°F) and 6.7°C (44.1°F).\\n\\n### Temperature\\n\\nJanuary proves to be the coldest month, recording an average maximum temperature of 17.3°C (63.1°F) and a minimum temperature of 6.7°C (44.1°F).\\n\\n### Humidity\\n\\nThe average relative humidity in January is 40%.\\n\\n### Rainfall\\n\\nIn Wah, in January, during 5.7 rainfall days, 27mm (1.06\") of precipitation is typically accumulated. In Wah, during the entire year, the rain falls for 113.1 days and collects up to 486mm (19.13\") of precipitation.\\n\\n### Daylight',\n",
       "  'score': 0.9998952}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"What is the weather in Wahcantt, Pakistan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ee6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "EMBED_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)\n",
    "\n",
    "loader = WebBaseLoader(\"https://wiki.luckfox.com/Luckfox-Pico-Plus-Mini/RKNN/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a60aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='78ad607b-fa6b-4109-9e09-99fbd2f1c28e', metadata={'source': 'https://wiki.luckfox.com/Luckfox-Pico-Plus-Mini/RKNN/', 'title': 'RKNN | LUCKFOX WIKI', 'description': 'RKNN 基础搭建和示例程序', 'language': 'en-US'}, page_content='RKNN | LUCKFOX WIKI')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is RKNN? \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e29e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2cd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"rockchip_rknn\",\n",
    "    \"Information about Rockchip RKNN. For any questions about Rockchip RKNN, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b96ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc621cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "007e8feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d562ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39aed9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rockchip RKNN is a deep learning framework and neural network inference engine developed by Rockchip, a Chinese fabless semiconductor company. RKNN is designed to run on Rockchip's SoC (System-on-Chip) processors, which are commonly used in a wide range of devices such as mobile phones, tablets, smart TVs, and set-top boxes.\\n\\nRKNN is based on the OpenVINO and TensorFlow frameworks and is optimized for Rockchip's hardware architecture, which includes a heterogeneous computing architecture that combines CPU, GPU, and NPU (Neural Processing Unit) resources.\\n\\nRKNN provides several benefits, including:\\n\\n1. **High-performance inference**: RKNN is optimized for Rockchip's hardware architecture, resulting in fast and efficient neural network inference.\\n2. **Low power consumption**: RKNN is designed to run on low-power devices, making it suitable for battery-powered devices.\\n3. **Easy deployment**: RKNN provides a simple and intuitive API for deploying neural networks on Rockchip devices.\\n4. **Cross-platform support**: RKNN supports a wide range of operating systems, including Android, Linux, and Windows.\\n\\nRKNN is commonly used in applications such as:\\n\\n1. **Computer vision**: RKNN is used for tasks like image recognition, object detection, and facial recognition.\\n2. **Speech recognition**: RKNN is used for speech recognition and natural language processing.\\n3. **Robotics**: RKNN is used for robotics applications, such as object detection and tracking.\\n4. **IoT**: RKNN is used for IoT applications, such as smart home devices and industrial automation.\\n\\nOverall, Rockchip RKNN is a powerful and efficient deep learning framework and neural network inference engine that is well-suited for a wide range of applications on Rockchip devices.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"what is Rockchip RKNN?\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9955a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc2606f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'rockchip_rknn', 'args': {'query': 'what is Rockchip RKNN?'}, 'id': 'k7sash537', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"what is Rockchip RKNN?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a36402",
   "metadata": {},
   "source": [
    "# Create the agent\n",
    "\n",
    "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent - for more information on this type of agent, as well as other options, see this guide.\n",
    "\n",
    "We can first choose the prompt we want to use to guide the agent.\n",
    "\n",
    "If you want to see the contents of this prompt and have access to Groq, you can go to:\n",
    "\n",
    "https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe1be143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages', 'tools'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000238B6625D00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000238B6625D00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], input_types={}, partial_variables={}, template='You are a helpful assistant. You have access to the following tools: {tools}. Use them when necessary to answer questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Create a custom prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. You have access to the following tools: {tools}. Use them when necessary to answer questions.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553afb5",
   "metadata": {},
   "source": [
    "Now, we can initialize the agent with the LLM, the prompt, and the tools. The agent is responsible for taking in input and deciding what actions to take. Crucially, the Agent does not execute those actions - that is done by the AgentExecutor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3475b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool use. Specifically, this json blob must be the last thing in your response before a newline. Here is the schema:\\n```\\n{{\"tool\": <tool name>, \"tool_input\": <parameters>}}\\n```\\n\\nAlways include a `tool_input` key in the blob, even if it is an empty dict.\\n\\nRespond in the same language the human is using.'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='messages'),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since langchain-hub is not available, we can use the ChatPromptTemplate we already created\n",
    "# The prompt structure from hwchase17/openai-functions-agent follows this pattern:\n",
    "# A system message with tool descriptions, followed by messages and agent scratchpad\n",
    "\n",
    "# Alternative: Pull the prompt manually by recreating the template\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# This mirrors the hwchase17/openai-functions-agent prompt structure\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool use. Specifically, this json blob must be the last thing in your response before a newline. Here is the schema:\n",
    "```\n",
    "{{\"tool\": <tool name>, \"tool_input\": <parameters>}}\n",
    "```\n",
    "\n",
    "Always include a `tool_input` key in the blob, even if it is an empty dict.\n",
    "\n",
    "Respond in the same language the human is using.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a78c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000248893523C0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Extract the system message from the prompt template\n",
    "system_message = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool use. Specifically, this json blob must be the last thing in your response before a newline. Here is the schema:\n",
    "```\n",
    "{\"tool\": <tool name>, \"tool_input\": <parameters>}\n",
    "```\n",
    "\n",
    "Always include a `tool_input` key in the blob, even if it is an empty dict.\n",
    "\n",
    "Respond in the same language the human is using.\"\"\"\n",
    "\n",
    "# Create the agent with the model, tools, and system prompt\n",
    "agent = create_agent(model, tools, system_prompt=system_message)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e00c61bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: {'messages': [HumanMessage(content='What is Rockchip RKNN?', additional_kwargs={}, response_metadata={}, id='d67ae08b-c9f1-46bc-938a-3ad86857f744'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8wkqg5xty', 'function': {'arguments': '{\"query\":\"What is Rockchip RKNN?\"}', 'name': 'rockchip_rknn'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 486, 'total_tokens': 535, 'completion_time': 0.085147273, 'completion_tokens_details': None, 'prompt_time': 0.026866446, 'prompt_tokens_details': None, 'queue_time': 0.005112784, 'total_time': 0.112013719}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfd52-5232-75f3-b48f-a51fe3802a48-0', tool_calls=[{'name': 'rockchip_rknn', 'args': {'query': 'What is Rockchip RKNN?'}, 'id': '8wkqg5xty', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 486, 'output_tokens': 49, 'total_tokens': 535}), ToolMessage(content=\"computations. To meet the demands of artificial intelligence, Rockchip has gradually integrated NPUs into its processors. The NPU integrated into Rockchip processors is called RKNPU. The LuckFox Pico series development board is equipped with Rockchip RV1103/RV1106 chips, which feature Rockchip's 4th generation self-developed NPU. This NPU boasts high computational precision and supports mixed quantization of int4, int8, and int16. RKNPU4.0 is subdivided into RKNPU2, so using RKNPU2 SDK and toolkits is necessary.2. Introduction to RKNN-Toolkit2\\u200bRKNN-Toolkit2 provides C or Python interfaces on the PC platform to simplify the deployment and execution of models. Users can easily accomplish the following tasks with this tool: model conversion, quantization, inference, performance and memory evaluation, quantization accuracy analysis, and model encryption. The RKNN software stack assists users in deploying AI models to Rockchip chips quickly. The overall framework is as follows:To use\\n\\nevaluation, quantization accuracy analysis, and model encryption. The RKNN software stack assists users in deploying AI models to Rockchip chips quickly. The overall framework is as follows:To use RKNPU, users need to first run the RKNN-Toolkit2 tool on their computer to convert the trained model into the RKNN format model, and then deploy it on the development board using the RKNN C API or Python API. This section introduces how users can quickly use RKNPU on the Luckfox Pico series boards.3 Installation of RKNN-Toolkit2 (PC ubuntu22.04)\\u200b3.1 Local Installation\\u200bLocal InstallationOperating System VersionUbuntu18.04(x64)Ubuntu20.04(x64)Ubuntu22.04(x64)Python Version3.6/3.73.8/3.93.10/3.11Download RKNN-Toolkit2git clone https://github.com/rockchip-linux/rknn-toolkit2Install Python Environmentsudo apt-get updatesudo apt-get install python3 python3-dev python3-pipsudo apt-get install libxslt1-dev zlib1g zlib1g-dev libglib2.0-0 libsm6 libgl1-mesa-glx libprotobuf-dev gccInstall RKNN-Toolkit2\\n\\nOptional. Can be specified as i8 or fp. i8 indicates quantization, fp indicates no quantization. Default is i8.<output_rknn_path>: Optional. Specifies the path to save the RKNN model. Defaults to the same directory as the ONNX model, named 'yolov5.rknn'.6.2 Compilation and Building\\u200bAfter successfully converting the ONNX model to RKNN model, perform cross-compilation on the rknn_model_zoo/examples/yolov5 directory. Set the following environment variables before compiling:export GCC_COMPILER=<SDK path>/tools/linux/toolchain/arm-rockchip830-linux-uclibcgnueabihf/bin/arm-rockchip830-linux-uclibcgnueabihfExecute the build-linux.sh script in the rknn_model_zoo directory to compile the example:chmod +x ./build-linux.sh./build-linux.sh -t rv1106 -a armv7l -d yolov5编译过程：(RKNN-Toolkit2) luckfox@luckfox:~/rknn_model_zoo$ ./build-linux.sh -t rv1106 -a armv7l -d yolov5./build-linux.sh -t rv1106 -a armv7l -d\\n\\nRKNN | LUCKFOX WIKI\", name='rockchip_rknn', id='743357c6-8736-4baf-9621-09bc72504a1f', tool_call_id='8wkqg5xty'), AIMessage(content='{\"tool\": \"tavily_search_results_json\", \"tool_input\": {\"query\": \"Rockchip RKNN\"}}', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1268, 'total_tokens': 1293, 'completion_time': 0.03052689, 'completion_tokens_details': None, 'prompt_time': 0.078000326, 'prompt_tokens_details': None, 'queue_time': 0.005383225, 'total_time': 0.108527216}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfd52-537a-7c33-83c5-a494ce28babe-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1268, 'output_tokens': 25, 'total_tokens': 1293})]}\n"
     ]
    }
   ],
   "source": [
    "# The agent created with create_agent is a compiled state graph that can be invoked directly\n",
    "# No need for AgentExecutor - just invoke the agent with input\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=\"What is Rockchip RKNN?\")]})\n",
    "print(f\"Final Response: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f38f1",
   "metadata": {},
   "source": [
    "# Adding in memory\n",
    "\n",
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in previous chat_history. Note: it needs to be called chat_history because of the prompt we are using. If we use a different prompt, we could change the variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e07d9036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'messages': [HumanMessage(content='hi! my name is Abdullah', additional_kwargs={}, response_metadata={}, id='cccbb27d-f33b-4195-a4c9-65bd10c78571'), AIMessage(content=\"Nice to meet you, Abdullah! What brings you here today? Do you have any questions or topics you'd like to discuss?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 485, 'total_tokens': 512, 'completion_time': 0.038273666, 'completion_tokens_details': None, 'prompt_time': 0.026852429, 'prompt_tokens_details': None, 'queue_time': 0.005082782, 'total_time': 0.065126095}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfd59-a9f5-7042-a0cb-d34c0c54f5d8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 485, 'output_tokens': 27, 'total_tokens': 512})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create an AgentExecutor-like wrapper for memory support\n",
    "class AgentExecutor:\n",
    "    def __init__(self, agent, tools):\n",
    "        self.agent = agent\n",
    "        self.tools = tools\n",
    "        self.chat_history = []\n",
    "    \n",
    "    def invoke(self, input_dict):\n",
    "        \"\"\"\n",
    "        Invoke the agent with memory support\n",
    "        input_dict should contain:\n",
    "        - \"input\": the user's question\n",
    "        - \"chat_history\": list of previous messages (optional)\n",
    "        \"\"\"\n",
    "        user_input = input_dict.get(\"input\", \"\")\n",
    "        chat_history = input_dict.get(\"chat_history\", [])\n",
    "        \n",
    "        # Combine chat history with current input\n",
    "        messages = chat_history + [HumanMessage(content=user_input)]\n",
    "        \n",
    "        # Invoke the agent\n",
    "        result = self.agent.invoke({\"messages\": messages})\n",
    "        \n",
    "        # Store in memory\n",
    "        self.chat_history = messages\n",
    "        if isinstance(result, dict) and \"messages\" in result:\n",
    "            self.chat_history.extend(result[\"messages\"])\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Create agent executor with memory\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "# Test with memory\n",
    "response = agent_executor.invoke({\"input\": \"hi! my name is Abdullah\", \"chat_history\": []})\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bf76989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi! my name is Abdullah', additional_kwargs={}, response_metadata={}, id='7b2f63b0-7fa8-47cc-b90a-566346aabdbc'),\n",
       "  AIMessage(content=\"Nice to meet you, Abdullah! It's great to have you here. Is there anything I can help you with, or would you like to chat for a bit? \\n\\n{tools}\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 485, 'total_tokens': 524, 'completion_time': 0.051938676, 'completion_tokens_details': None, 'prompt_time': 0.026732092, 'prompt_tokens_details': None, 'queue_time': 0.004979462, 'total_time': 0.078670768}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfd5a-4b56-7070-960d-c733508cc969-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 485, 'output_tokens': 39, 'total_tokens': 524})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi! my name is Abdullah\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5c5dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "793d9b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi! my name is Abdullah', additional_kwargs={}, response_metadata={}, id='2ec0f983-94b0-4694-9b80-91455b524c5a'),\n",
       "  AIMessage(content='Hello Abdullah! How can I assist you today?', additional_kwargs={}, response_metadata={}, id='f150f165-58f3-4fcd-889b-e2681345cd43', tool_calls=[], invalid_tool_calls=[]),\n",
       "  HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='524ad666-7901-46cb-81bb-dbb43cc15ec6'),\n",
       "  AIMessage(content='Your name is Abdullah.\\n\\n{tool: \"answer\", \"tool_input\": {\"question\": \"what\\'s my name?\", \"context\": {\"name\": \"Abdullah\"}}}', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 510, 'total_tokens': 547, 'completion_time': 0.065027335, 'completion_tokens_details': None, 'prompt_time': 0.027980487, 'prompt_tokens_details': None, 'queue_time': 0.005129067, 'total_time': 0.093007822}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfd5b-92d3-7b02-b026-98f8aaddbc35-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 510, 'output_tokens': 37, 'total_tokens': 547})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is Abdullah\"),\n",
    "            AIMessage(content=\"Hello Abdullah! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "404325f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3791ff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AgentExecutor' object has no attribute 'with_listeners'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m agent_with_chat_history = \u001b[43mRunnableWithMessageHistory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_session_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_messages_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory_messages_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchat_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Agentic AI Bootcamp_2\\langchain_tool_callling\\venv\\Lib\\site-packages\\langchain_core\\runnables\\history.py:332\u001b[39m, in \u001b[36mRunnableWithMessageHistory.__init__\u001b[39m\u001b[34m(self, runnable, get_session_history, input_messages_key, output_messages_key, history_messages_key, history_factory_config, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m messages_key:\n\u001b[32m    328\u001b[39m     history_chain = RunnablePassthrough.assign(\n\u001b[32m    329\u001b[39m         **{messages_key: history_chain}\n\u001b[32m    330\u001b[39m     ).with_config(run_name=\u001b[33m\"\u001b[39m\u001b[33minsert_history\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m runnable_sync: Runnable = \u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_listeners\u001b[49m(on_end=\u001b[38;5;28mself\u001b[39m._exit_history)\n\u001b[32m    333\u001b[39m runnable_async: Runnable = runnable.with_alisteners(on_end=\u001b[38;5;28mself\u001b[39m._aexit_history)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_runnable_sync\u001b[39m(_input: Any) -> Runnable:\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentExecutor' object has no attribute 'with_listeners'"
     ]
    }
   ],
   "source": [
    "# Wrap the agent (not the AgentExecutor) with message history\n",
    "# The agent itself is a Runnable, so it works with RunnableWithMessageHistory\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent,  # Use the agent directly, not agent_executor\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    history_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "# Test it - invoke with session_id for automatic history management\n",
    "response = agent_with_chat_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi! My name is Umair\")]},\n",
    "    config={\"configurable\": {\"session_id\": \"user123\"}}\n",
    ")\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
